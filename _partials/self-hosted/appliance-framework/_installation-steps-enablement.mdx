---
partial_category: self-hosted
partial_name: installation-steps-enablement
---

1. Download the {props.iso} ISO from the Artifact Studio. Refer to the Artifact Studio (link TBC) guide for
   instructions on how to access and download the ISO.

2. Upload the ISO to your infrastructure provider. This can be done using the web interface of your infrastructure
   provider or using command-line tools.

   - For VMware vSphere, you can upload the ISO to a datastore using the vSphere Client or the `govc` CLI tool.
   - For Bare Metal, you can use tools like `scp` or `rsync` to transfer the ISO to the nodes, or use a USB drive to
     boot the nodes from the ISO.
   - For Machine as a Service (MAAS), you can use the MAAS web interface to upload the ISO.

   Ensure that the ISO is accessible to all nodes that will be part of the {props.version} management cluster.

3. Boot each node from the ISO to install the necessary software for {props.version}. The installation process will
   automatically configure the nodes with the required components, including the operating system, Kubernetes, CNI, and
   CSI.

4. Once the nodes have booted from the ISO, they will automatically start the installation process. The GRand Unified
   Bootloader (GRUB) screen may be displayed with selectable options; this should be ignored as the installation will
   proceed automatically.

   Wait for the installation process to complete. This will take at least 15 minutes, depending on the resources
   available on the nodes. After completion, the nodes will reboot and display the Palette Terminal User Interface
   (TUI).

5. Log in to the nodes using the default credentials for Kairos Ubuntu. The default username is `kairos`, and the
   password is `kairos`.

6. In the Palette TUI, configure the nodes as per your environment requirements. Use the **TAB** key or the up and down
   arrow keys to switch between fields. When you make a change, press **ENTER** to apply the change. Use **ESC** to go
   back.

7. In **Hostname**, check the existing hostname and, optionally, change it to a new one.

8. In **Host Network Adapters**, select a network adapter you would like to configure. By default, the network adapters
   request an IP automatically from the Dynamic Host Configuration Protocol (DHCP) server. The CIDR block of an
   adapter's possible IP address is displayed in the **Host Network Adapters** screen without selecting an individual
   adapter.

   In the configuration page for each adapter, you can change the IP addressing scheme of the adapter and choose a static
   IP instead of DHCP. In Static IP mode, you will need to provide a static IP address and subnet mask, as well as the
   address of the default gateway. Specifying a static IP will remove the existing DHCP settings.

   You can also specify the Maximum Transmission Unit (MTU) for your network adapter. The MTU defines the largest size,
   in bytes, of a packet that can be sent over a network interface without needing to be fragmented.

9. In **DNS Configuration**, specify the IP address of the primary and alternate name servers. You can optionally
   specify a search domain.

10. After you are satisfied with the configurations, navigate to **Quit** and press **ENTER** to finish the
    configuration. Press **ENTER** again on the confirmation prompt.

    After a few seconds, the terminal displays the **Device Info** and prompts you to provision the device through Local UI.

11. Ensure you complete the configuration on each node before proceeding to the next step.

12. Decide on the host that you plan to use as the leader of the group. Refer to <VersionedLink text="Link Hosts" url="/clusters/edge/local-ui/cluster-management/link-hosts#leader-hosts"/> for more information about leader hosts.

13. Access the Local UI of the leader host. Local UI is used to manage the {props.version} nodes and perform administrative
    tasks. It provides a web-based interface for managing the {props.version} management cluster.

    In your web browser, go to `https://<node-ip>:5080`. Replace `<node-ip>` with the IP address of your node. If you
    have changed the default port of the console, replace `5080` with the Local UI port. The address of the Local UI console
    is also displayed on the terminal screen of the node.

    If you are accessing Local UI for the first time, a security warning may be displayed in your web browser. This
    is because Local UI uses a self-signed certificate. You can safely ignore this warning and proceed to Local
    UI.

14. Log in to Local UI using the default credentials. The default username is `kairos`, and the password is `kairos`. You
    can change the password after logging in.

15. Click the **User Menu** in the top-right corner and select **Update password**. Provide the **Old
    Password** (`kairos`), and set a new password in the **New Password** field. This will be the password you use to
    log in to Local UI in the future.

16. (Optional) If you need to configure a HTTP proxy server for the node, follow the steps in the <VersionedLink text="Configure HTTP-Proxy in Local UI" url="/clusters/edge/local-ui/host-management/configure-proxy"/> guide. When done, proceed to the next step.

17. From the left main menu, click **Linked Edge Hosts**.

18. Click **Generate token**. The host begins generating tokens that you will use to link this host with other
    hosts. The Base64 encoded token contains the IP address of the host, as well as an OTP that will expire in two
    minutes. Once a token expires, the leader generates another token automatically.

19. Click the **Copy** button to copy the token.

20. Log in to Local UI on the host that you want to link to the leader host.

21. From the left main menu, click **Linked Edge Hosts**.

22. Click **Link this device to another**.

23. In the pop-up box that appears, enter the token you copied from the leader host.

24. Click **Confirm**.

25. Repeat steps 20-24 for every host you want to link to the leader host.

26. Confirm that all linked hosts appear in the **Linked Edge Hosts** table. The following columns should show the
    required statuses:

    - **Status** = Ready
    - **Content** = Synced
      - Content synchronization will take at least five minutes to complete, depending on your network resources.
    - **Health** = Healthy

27. On the left main menu, click **Cluster**.

28. Click **Create cluster**.

29. For **Basic Information**, provide a name for the cluster and optional tags in `key:value` format.

30. In **Cluster Profile**, the **Imported Applications preview** section displays the applications that are included
    with the {props.app}. These applications are pre-configured and used to deploy your {props.version} management
    cluster.

    Leave the default options in place and click **Next**.

31. In **Profile Config**, configure the cluster profile settings to your requirements. Review the following tables for
    the available options.

    #### Cluster Profile Options

    | **Option**                        | **Description**                                                                                                                                 | **Type**      | **Default**          |
    | --------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | -------------------- |
    | **Pod CIDR**                      | The CIDR range for the pod network. This is used to allocate IP addresses to pods in the cluster.                                               | CIDR notation | **`192.168.0.0/16`** |
    | **Service CIDR**                  | The CIDR range for the service network. This is used to allocate IP addresses to services in the cluster.                                       | CIDR notation | **`192.169.0.0/16`** |
    | **Ubuntu Pro Token (Optional)**   | The token for your [Ubuntu Pro](https://ubuntu.com/pro) subscription.                                                                           | String        | _No default_         |
    | **Storage Pool Drive (Optional)** | The storage pool device to use for the cluster. As mentioned in the [Prerequisites](#prerequisites), assign this to your second storage device. | String        | **`/dev/sdb`**       |

    #### Registry Options

    | **Option**                                    | **Description**                                                                                                                                                                                                                                                                                              | **Type**              | **Default**                               |
    | --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------- | ----------------------------------------- |
    | **OCI Registry Base Content Path (Optional)** | The base path for the registry content for the internal or external registry. {props.version} packs will be stored in this directory.                                                                                                                                                                                | String                | **`spectro-content`**                     |
    | **Registry Username**                         | If using the internal Zot registry, leave the default username or adjust to your requirements. If using an external registry, provide the appropriate username.                                                                                                                                          | String                | **`admin`**                               |
    | **OCI Pack Registry Password**                | If using the internal Zot registry, change the password to your requirements. If using an external registry, provide the appropriate password.                                                                                                                                                               | String                | **`Spectro@123`**                         |
    | **OCI Pack Registry Ca Cert (Optional)**      | The CA certificate that was used to sign the registry certificate.                                                                                                                                                                                                                                           | Base64 encoded string | _No default_                              |
    | **Root Domain (Optional)**                    | The root domain for the registry. The default is set for the internal Zot registry, which is a virtual IP address assigned by [kube-vip](https://kube-vip.io/). If using an external registry, adjust this to the appropriate domain. This must match the root domain specified in the registry certificate. | String                | **`{{.spectro.system.cluster.kubevip}}`** |
    | **Mongo Replicas (Optional)**                 | The number of MongoDB replicas to create for the cluster. The accepted values are `1` or `3`. We recommend using **3** to provide high availability for the MongoDB database.                                                                                                                            | Integer               | **`3`**                                   |
    | **Registry Port**                             | The port for the registry. The default value can be changed for the internal Zot registry. Adjust if using an external registry.                                                                                                                                                                             | Integer               | **`30003`**                               |
    | **Registry Private Cert Key**                 | The private key for the registry certificate used for TLS encryption.                                                                                                                                                                                                                                        | Base64 encoded string | _No default - must be provided_           |
    | **Registry Cert**                             | The certificate for the registry used for TLS encryption.                                                                                                                                                                                                                                                    | Base64 encoded string | _No default - must be provided_           |
    | **Registry Endpoint**                         | The DNS/IP endpoint for the registry. Leave the default entry if using the internal Zot registry, which is a virtual IP address assigned by [kube-vip](https://kube-vip.io/). Adjust if using an external registry.                                                                                          | String                | **`{{.spectro.system.cluster.kubevip}}`** |
    | **In Cluster Registry (Optional)**            | - `True` - Use internal Zot registry <br /> - `False` - Use external registry.                                                                                                                                                                                                                                     | Boolean               | **True**                                  |
    | **Image Replacement Rules (Optional)**        | Set rules for replacing image references when using an external registry. For example, `old-registry.com/new-registry.com`. Leave empty if using the internal Zot registry.                                                                                                                                  | String                | _No default_                              |

32. Click **Next** when you are done.

33. In **Cluster Config**, configure the following options.

    #### Cluster Config Options

    | **Option**                                 | **Description**                                                                                | **Type** | **Default**  |
    | ------------------------------------------ | ---------------------------------------------------------------------------------------------- | -------- | ------------ |
    | **Network Time Protocol (NTP) (Optional)** | The NTP servers to synchronize time within the cluster.                                        | String   | _No default_ |
    | **SSH Keys (Optional)**                    | The public SSH keys to access the cluster nodes. Add additional keys by clicking **Add Item**. | String   | _No default_ |
    | **Virtual IP Address (VIP)**               | The virtual IP address for the cluster. This is used for load balancing and high availability. | String   | _No default_ |

    Click **Next** when you are done.

34. In **Node Config**, configure the following options.

    :::important

    We recommend having at least three control plane nodes for high availability. You can remove the worker node
    pool as it is not required for the {props.version} management cluster. If doing this, ensure that the **Allow worker
    capability** option is enabled for the control plane node pool.

    :::

    #### Node Pool Options

    <Tabs>

    <TabItem value="control-plane-pool-options" label="Control Plane Pool Options">

    | **Option**                                       | **Description**                                                                                                                                                       | **Type**                                             | **Default**              |
    | ------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- | ------------------------ |
    | **Node pool name**                               | The name of the control plane node pool. This will be used to identify the node pool in {props.version}.                                                                      | String                                               | **`control-plane-pool`** |
    | **Allow worker capability (Optional)**           | Whether to allow workloads to be scheduled on this control plane node pool. Ensure that this is enabled if no worker pool is assigned to the cluster.                 | Boolean                                              | **True**                 |
    | **Additional Kubernetes Node Labels (Optional)** | Tags for the node pool in `key:value` format. These tags can be used to filter and search for node pools in {props.version}.                                                  | String                                               | _No default_             |
    | **Taints**                                       | Taints for the node pool in `key=value:effect` format. Taints are used to prevent pods from being scheduled on the nodes in this pool unless they tolerate the taint. | - **Key** = string <br />- **Value** = string<br />- **Effect** = string (enum) | _No default_             |

    </TabItem>

    <TabItem value="worker-pool-options" label="Worker Pool Options">

    | **Option**                                       | **Description**                                                                                                                                                       | **Type**                                             | **Default**       |
    | ------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- | ----------------- |
    | **Node pool name**                               | The name of the worker node pool. This will be used to identify the node pool in {props.version}.                                                                             | String                                               | **`worker-pool`** |
    | **Additional Kubernetes Node Labels (Optional)** | Tags for the node pool in `key:value` format. These tags can be used to filter and search for node pools in {props.version}.                                                  | String                                               | _No default_      |
    | **Taints**                                       | Taints for the node pool in `key=value:effect` format. Taints are used to prevent pods from being scheduled on the nodes in this pool unless they tolerate the taint. | - **Key** = string <br />- **Value** = string<br />- **Effect** = string (enum) | _No default_      |

    </TabItem>

    </Tabs>

    ##### Pool Configuration

    The following options are available for both the control plane and worker node pools. You can configure these
    options to your requirements. You can also remove worker pools if not needed.

    | **Option**               | **Description**                                                                                                                                                                           | **Type**      | **Default**                                                                                      |
    | ------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- | ------------------------------------------------------------------------------------------------ |
    | **Architecture**         | The CPU architecture of the nodes. This is used to ensure compatibility with the applications operating on the nodes.                                                                       | String (enum) | **`amd64`**                                                                                      |
    | **Add Edge Hosts**       | Click **Add Item** and select the other hosts that you installed using the {props.app} ISO. These hosts will be added to the node pool. Each pool must contain at least one node. | N/A           | - **Control Plane Pool** = _Current host selected_ <br /> - **Worker Pool** = _No host selected_ |
    | **NIC Name**             | The name of the network interface card (NIC) to use for the nodes. Leave on **Auto** to let the system choose the appropriate NIC, or select one manually from the drop-down menu.        | N/A           | **Auto**                                                                                         |
    | **Host Name (Optional)** | The hostname for the nodes. This is used to identify the nodes in the cluster. A generated hostname is provided automatically, which you can adjust to your requirements.                   | String        | **`edge-*`**                                                                                     |

35. Click **Next** when you are done.

36. In **Review**, check that your configuration is correct. If you need to make changes, click on any of the sections
    in the left sidebar to go back and edit the configuration.

    When you are satisfied with your configuration, click **Deploy Cluster**. This will start the cluster creation
    process.

    The cluster creation process will take 20 to 30 minutes to complete. You can monitor progress from the **Overview** tab
    on the **Cluster** page in the left main menu. The cluster is fully provisioned when the status changes to
    **Running** and the health status is **Healthy**.

37. Once the cluster is provisioned, access the {props.version} system console using the virtual IP address (VIP) you configured
    earlier. Open your web browser and go to `https://<vip-address>/system`. Replace `<vip-address>` with the VIP you
    configured for the cluster.

    The first time you visit the system console, a warning message about an untrusted TLS certificate may appear. This
    is expected, as you have not yet uploaded your TLS certificate. You can ignore this warning message and proceed.

38. You will be prompted to log in to {props.version} system console. Use `admin` as the username and `admin` as the password.
    You will be prompted to change the password after logging in.

39. In the **Account Info** window, provide the following information:

    - **Email address** - This is used for notifications and password recovery as well as logging in to the {props.version}
      system console.
      - This will not be active until you <PaletteVertexUrlMapper edition={props.edition} text="configure SMTP settings" url="/system-management/smtp"/> in {props.version} system console and verify your email address.
    - **Current password** - Use `admin` as the current password.
    - **New password** - Enter a new password for the account.
    - **Confirm new password** - Re-enter the new password for confirmation.

    Refer to <PaletteVertexUrlMapper edition={props.edition} text="Password Requirements and Security" url="/system-management/account-management/credentials#password-requirements-and-security"/> to learn about password requirements.

After logging in, a summary page is displayed. You now have access to the {props.version} system console, where you can manage your
{props.version} environment.

If you are accessing the {props.version} system console for the first time, a security warning may be displayed in your web
browser. This is because {props.version} is configured with a self-signed certificate. You can replace the self-signed
certificate with your own SSL certificates as guided later in [Next Steps](#next-steps).